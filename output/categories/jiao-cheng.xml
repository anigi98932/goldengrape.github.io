<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet type="text/xsl" href="../assets/xml/rss.xsl" media="all"?><rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>GoldenGrape's Blog (文章分类：教程)</title><link>https://goldengrape.github.io/</link><description></description><atom:link href="https://goldengrape.github.io/categories/jiao-cheng.xml" rel="self" type="application/rss+xml"></atom:link><language>zh_cn</language><copyright>Contents © 2018 &lt;a href="mailto:https://twitter.com/goldengrape"&gt;Golden Grape&lt;/a&gt; </copyright><lastBuildDate>Fri, 09 Feb 2018 05:17:20 GMT</lastBuildDate><generator>Nikola (getnikola.com)</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>中国古代数学算法的Python实现</title><link>https://goldengrape.github.io/posts/python/python-old-chinese/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;p&gt;看了这篇《&lt;a href="https://mp.weixin.qq.com/s?__biz=MzA5NDkzNjIwMg==&amp;amp;mid=2651662431&amp;amp;idx=1&amp;amp;sn=21ae67f8ed94ea960d92734afc384fc1&amp;amp;chksm=8bbe85babcc90cac200fabd65d5494bbbec81792420ba8771ad02bc324257495cffdcd57afcd"&gt;没有定理的中国古代数学，如何站在世界之巅？&lt;/a&gt;》。虽然我觉得题目很标题党，不过里面的内容很有趣啊，讲解了中国古代数学里的几个算法。由于我正在学Python，所以自然就拿来练手了。&lt;/p&gt;
&lt;p&gt;可以运行的代码&lt;a href="https://repl.it/HgCF/30"&gt;在这里&lt;/a&gt;
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;更相减损术&lt;/h2&gt;
&lt;p&gt;“术曰：以少减多，更相减损，求其等也。”&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;def 更相减损术(a,b):
    while (a != b):
        if a &amp;gt; b:
            a=a-b
        else :
            b=b-a
    return a
&lt;/pre&gt;


&lt;p&gt;这个很好写啦，读入两个数a和b，求其等也，就是一直要求到两个数相等为止。
所以用条件循环while，当a不等于b时就一直重复算。算什么呢，以少减多，就是判断一下谁大.
如果a&amp;gt;b, 就用a-b替换a，否则就用b-a替换b。
一直到两个数减到相等为止，就可以随便返回其中一个数作为最大公约数了。&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;大衍求一术&lt;/h2&gt;
&lt;p&gt;这个好帅，是求解ax≡1(mod b)。就是说a乘以x除以b所得的余数等于1。详细的解说还是看那篇公众号的文章吧。&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;def 大衍求一术(a,b):
    m=np.matrix( [ [a,1], [b,0] ] )
    while (m[0,0] != 1 ):
        if m[0,0]&amp;gt;m[1,0]:
            m[0,:]=m[0,:]-m[1,:]
        else:
            m[1,:]=m[1,:]-m[0,:]
        if m[1,0]==1:
            return 1
        else:
            return m[0,1]
&lt;/pre&gt;


&lt;p&gt;因为打算用矩阵，所以要首先导入Numpy包，python很强大的一点就是有各种包，只要import一下就好像有了超能力。
大衍求一术要求先生成一个2*2的矩阵&lt;/p&gt;
&lt;pre class="code literal-block"&gt;&lt;span&gt;&lt;/span&gt;a 1
b 0
&lt;/pre&gt;


&lt;p&gt;这样的，所以先用np.matrix产生一个矩阵m，注意python的序数是从0开始的，所以m[0,0]=a, m[0,1]=1, m[1,0]=b, m[1,1]=0。&lt;/p&gt;
&lt;p&gt;然后跟前面的更相减损术差不多，也是减来减去，区别是以行为单位来减，终点是把a的位置变成1，比大小的时候是用左边那列的元素比大小。&lt;/p&gt;
&lt;p&gt;所以如果m[0,0]&amp;gt;m[1,0]，那就把上一行减去下一行m[0,:]-m[1,:]，再替换掉上面一行m[0,:]=m[0,:]-m[1,:]。反之亦然。一直重复，直到m[0,0] == 1。&lt;/p&gt;
&lt;p&gt;通常是返回m[0,1]的数值就可以了。但有可能a,b互质，所以需要分情况讨论一下。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;我的古文水平和编程水平都还不够高，不然把中国古代数学中的种种算法都写出程序也是一件很风雅的事情。&lt;/p&gt;&lt;/div&gt;</description><category>教程</category><guid>https://goldengrape.github.io/posts/python/python-old-chinese/</guid><pubDate>Thu, 28 Dec 2017 07:00:15 GMT</pubDate></item><item><title>快速绘制操作示意图</title><link>https://goldengrape.github.io/posts/ophthalmology/make-simple-fig/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;p&gt;先展示几张效果图：
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/01.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/02.jpg"&gt;&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;需要的的APP
在iOS上&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;adobe draw&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;adobe capture&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;在android上&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;adobe draw&lt;/li&gt;
&lt;li&gt;adobe gather&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;注意在android上，adobe draw和gather之间并没有非常好的衔接，还是需要同步到adobe的库中以后才能调用，而adobe服务器从国内访问的速度又很慢。&lt;/p&gt;
&lt;p&gt;但，我有iPad，哪管android上的好用不好用。反正iPad上挺好用的。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/03.jpg"&gt;&lt;/p&gt;
&lt;p&gt;1 拍照
对常见场景拍照，比如手持器械的照片，或者需要讲解的场景。&lt;/p&gt;
&lt;p&gt;尽量在白色背景上照相，比如白色桌面或者是白纸上。&lt;/p&gt;
&lt;p&gt;物体和手最好稍微离开桌面，以免留下明显的阴影。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/04.jpg"&gt;&lt;/p&gt;
&lt;p&gt;2 在adobe draw中新建图画，在图层中添加image layer，导入刚刚拍摄的场景照片。
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/05.jpg"&gt;
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/06.jpg"&gt;&lt;/p&gt;
&lt;p&gt;3 添加draw layer图层后，点击打开shape，然后点击“+”号，会自动切换至adobe capture。&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/07.jpg"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/08.jpg"&gt;&lt;/p&gt;
&lt;p&gt;在adobe capture中从camera roll中导入照片&lt;/p&gt;
&lt;p&gt;4 调整滑动条，使采集的图像仅仅保留边缘的线条，&lt;/p&gt;
&lt;p&gt;采集后清除多余的线条和杂点，&lt;/p&gt;
&lt;p&gt;在preview中，smooth选项推荐处于OFF关闭状态&lt;/p&gt;
&lt;p&gt;之后save &amp;amp; return to adobe draw（屏幕顶部橙色条）&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/09.jpg"&gt;
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/10.jpg"&gt;&lt;/p&gt;
&lt;p&gt;5 在新建的draw layer图层中，小心地用双手指调整shape的大小和位置，直到与底部的照片相吻合，然后双击屏幕，shape印章盖下。&lt;/p&gt;
&lt;p&gt;本层暂且称为浅色层
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/11.jpg"&gt;&lt;/p&gt;
&lt;p&gt;6 再次重复：&lt;/p&gt;
&lt;p&gt;新建draw layer图层，&lt;/p&gt;
&lt;p&gt;点击shape菜单，点击+，&lt;/p&gt;
&lt;p&gt;在adobe capture中导入照片。&lt;/p&gt;
&lt;p&gt;本次调整滑动条，向较深颜色方向移动，记录更多的细节。&lt;/p&gt;
&lt;p&gt;然后capture&lt;/p&gt;
&lt;p&gt;save &amp;amp; return
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/12.jpg"&gt;&lt;/p&gt;
&lt;p&gt;7 在adobe draw中新建的draw layer图层，&lt;/p&gt;
&lt;p&gt;调整好shape的位置后，双击屏幕，shape印章盖下&lt;/p&gt;
&lt;p&gt;本层暂且称为深色层&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/13.jpg"&gt;&lt;/p&gt;
&lt;p&gt;8 新建draw layer图层，&lt;/p&gt;
&lt;p&gt;用笔按照照片的提示描绘缺少边缘的细节，比如剪子尖端。不需要非常精细地描绘，&lt;/p&gt;
&lt;p&gt;用笔填充无用的空洞
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/14.jpg"&gt;&lt;/p&gt;
&lt;p&gt;9 在深色图层中&lt;/p&gt;
&lt;p&gt;用橡皮擦擦去多余的点、连成片的黑色区域，并适当使用笔补充边缘线条。&lt;/p&gt;
&lt;p&gt;完成后，将照片层隐藏，底色层隐藏，然后导出为图片，存入camera roll。
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/15.jpg"&gt;&lt;/p&gt;
&lt;p&gt;10 新建draw layer图层，隐藏其余所有图层，&lt;/p&gt;
&lt;p&gt;点击shape菜单中的“+”号，进入adobe capture，导入刚刚存入camera roll的线条图。&lt;/p&gt;
&lt;p&gt;稍微清理后，在preview中注意将smooth的开关打开至ON，&lt;/p&gt;
&lt;p&gt;完成后save &amp;amp; return to adobe draw
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/16.jpg"&gt;&lt;/p&gt;
&lt;p&gt;11 隐藏其他所有的图层，&lt;/p&gt;
&lt;p&gt;调整shape至合适的大小，双击屏幕，shape印章盖下。&lt;/p&gt;
&lt;p&gt;此图层为完成版，如果发现仍有细节需要修改，可以再次重复前面的步骤7-10&lt;/p&gt;
&lt;p&gt;完成后，可以导出图像至camera roll，供后续使用。
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/17.jpg"&gt;&lt;/p&gt;
&lt;p&gt;在写书或者做讲课课件时，可以用本方法制作很多操作示意图。我不确定手术过程中的照片是否容易用类似方法绘制，最差也可以用照片垫底，在上面有笔勾勒一些关键线条，总是比自己完全重绘要简单很多。&lt;/p&gt;
&lt;p&gt;对于已经制作好的图片，也可以再利用简单的图像编辑，甚至PPT，就可以更换器械，比如笔可以换成15度刀、月形刀、phaco手柄、chopper钩之类。上面做的拿剪子的动作，也很容易换成各种手术钳。
&lt;img alt="" src="https://goldengrape.github.io/images/%E6%89%8B%E7%BB%98/18.jpg"&gt;&lt;/p&gt;
&lt;p&gt;对于眼科的常用手术器械，我之前已经做过了。眼科大夫自用可以从下面链接下载：&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/goldengrape/phacoTools/raw/master/phaco%20tools.pptx"&gt;https://github.com/goldengrape/phacoTools/raw/master/phaco%20tools.pptx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;眼科公司商业使用请联系我。当然也欢迎各公司把自己的产品做成容易在PPT里编辑粘贴的图片，供医生写书和讲课使用。&lt;/p&gt;&lt;/div&gt;</description><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/ophthalmology/make-simple-fig/</guid><pubDate>Mon, 18 Dec 2017 18:36:43 GMT</pubDate></item><item><title>机器学习的战略(6)--end to end</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;h2&gt;端到端学习 end-to-end Learning&lt;/h2&gt;
&lt;p&gt;这个也是吓人.  读书人, 相煎何太急.&lt;/p&gt;
&lt;p&gt;end-to-end的一端是原始数据, 另一端是想要的结果. 比如也许从一张眼底照片+FFA直接给出眼底激光应该打哪里, 或者说中文直接给出翻译好的英文字幕. 从一端到另一端中间本来是有很多研究过程在里面的,
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;中文语音-&amp;gt;音频信号增强降噪-&amp;gt;音节提取-&amp;gt;转成文字-&amp;gt;翻译-&amp;gt;英文字幕,&lt;/li&gt;
&lt;li&gt;眼底照片+FFA-&amp;gt;数微血管瘤, 渗出-&amp;gt;形成糖尿病视网膜病变诊断-&amp;gt;分期-&amp;gt;判定新生血管-&amp;gt;规划激光点位置-&amp;gt;开打&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;每个环节都有一堆PhD论文, 有一堆临床经验, 现在突然有一部分问题可以直接跳过中间环节, 从一端直接获得另一端的结果. 有时候学术研究也堪比柯达胶卷, 明明自己很努力也没做错什么, 整个领域突然就废了.&lt;/p&gt;
&lt;p&gt;不过好在目前还不是所有的问题都可以end-to-end, 而且也不是end-to-end就效果很好. 有些问题加个中间环节反而可以更有效.&lt;/p&gt;
&lt;p&gt;课程中的例子是:
&lt;em&gt; 门禁的人脸识别, 一种是直接从图像-&amp;gt;身份ID的end-to-end, 另一种是图像-&amp;gt;标记出人脸-&amp;gt;剪裁图片人脸放大居中-&amp;gt;身份ID. 后者的效果更好.
&lt;/em&gt; 另一个例子是从X光片看儿童发育, 直接从图像-&amp;gt;年龄的效果不如图像-&amp;gt;提取分离骨骼图像-&amp;gt;骨骼尺寸-&amp;gt;年龄, 而且其中骨骼尺寸-&amp;gt;年龄是可以从正常值的统计得出的.&lt;/p&gt;
&lt;h2&gt;是否使用end-to-end&lt;/h2&gt;
&lt;p&gt;优点:
&lt;em&gt; 完全来自于数据, 机器学习"总结"出来的规律是客观数据所反映的, 不是人想象出来的, 用不着讨论是"木火土金水"还是"金木水火土"
&lt;/em&gt; 用不着太多手工设计.&lt;/p&gt;
&lt;p&gt;缺点:
&lt;em&gt; 需要大量大量大量大量的数据.
&lt;/em&gt; 排除了手工设计的组件.
    * 手工设计组件并非坏事, 人类的推理归纳还是对知识的扩展有很大意义.
    * 而且, 从我做发明的经验来看, 很多公司要求避免使用比较"黑箱"的深度学习方法, 大概很难查错吧.&lt;/p&gt;
&lt;p&gt;是否用end-to-end的关键在于, 已经拥有的data数量是否已经可以 &lt;strong&gt;足够&lt;/strong&gt; 反映出问题的复杂性. 足够的定义就只好靠经验和实践了.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/</guid><pubDate>Mon, 18 Dec 2017 17:23:43 GMT</pubDate></item><item><title>机器学习的战略(5)--迁移学习</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;h2&gt;迁移学习&lt;/h2&gt;
&lt;p&gt;好激动, 这是整个机器学习里面最激动人心最吸引人的部分了. 知道了迁移学习这事情以后, 我才比较理解为什么整个课程一直没有进入各种fancy的CNN, RNN之类的神经网络结构, 而仅仅就是把层次多一点的神经网络称为深度神经网络.
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;p&gt;迁移学习是说, 可以用训练好的神经网络稍微改改, 用自己的数据来训练最后几层. 比如可以用ImangeNet的优胜者模型, 类似GoogleNet, VGG之类, 这些网络模型是用来分类常规图像的, 比如阿猫阿狗, 但是可以固定前面层次的参数, 留出最后一两层的全连接神经网络, 用自己的数据, 比如眼底图片或者放射科影像来训练.&lt;/p&gt;
&lt;p&gt;这时候训练的数据量不需要很大, 至少不必像ImageNet那样的大量数据集了. 因为前面一些层次的神经元往往是用来提取图像的低级特征的, 类似提取边缘之类的.&lt;/p&gt;
&lt;p&gt;如果只训练了最后一个全连接层觉得效果不够好, 可以再逐渐加层次. 也就是把训练好的模型(如VGG)当作标准的特征提取器或者域变换操作, 先对数据进行预处理, 然后送进自己的神经网络.&lt;/p&gt;
&lt;p&gt;补充说一下, 由于迁移学习常用, 所以很多机器学习的框架例如tensorflow \ pytorch都有所谓的model zoo. 知名的模型已经都摆在zoo里面供大家挑选了.  &lt;/p&gt;
&lt;p&gt;这里面需要注意的是, 迁移学习用的模型数据形式至少要和目标是一样的, 比如用ImageNet竞赛获奖模型, 那么至少应该是用来看图的.&lt;/p&gt;
&lt;p&gt;然后, 吴恩达老师举例子的时候, 目标dataset的数据量终于从100k的数量级降到1k的数量级了. 突然觉得有希望能做东西了有没有.&lt;/p&gt;
&lt;h2&gt;多任务学习&lt;/h2&gt;
&lt;p&gt;这一部分离我远一些, 兴趣不大. 大概在自动驾驶的场景里比较多.&lt;/p&gt;
&lt;p&gt;与单独识别一张照片里有猫还是没猫不一样. 可以同时训练在图像里找到多个目标, 比如是否有红灯\是否有行人\是否有其他车辆, 这些事情要放在一起学, 不要单独训练是否有红灯, 再用另一组dataset训练是否有行人, 因为拆分了任务就很难保证足够大的dataset, 效果会差一些.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;update&lt;/p&gt;
&lt;p&gt;迁移学习也是有代价的, 继承深度神经网络的处理能力时, 也会继承神经网络内在的"错觉", 我觉得错觉比bug更能解释问题的所在. 从成本考虑, 我觉得未来肯定越来越多的应用是使用迁移学习来的, 被继承的深度神经网络只会是有限的几个. 会有一些针对性的错觉被发现, 甚至还可能会有共有的错觉.&lt;/p&gt;
&lt;p&gt;参考&lt;a href="https://www.wired.com/story/machine-learning-backdoors/"&gt;Even Artificial Neural Networks Can Have Exploitable 'Backdoors'&lt;/a&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi/</guid><pubDate>Mon, 18 Dec 2017 17:23:31 GMT</pubDate></item><item><title>机器学习的战略(4)--面对分布不同</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;p&gt;这一部分我在做练习题的时候老是错, 我都不是很确定自己理解明白了. 有必要的话最好还是回到课程原始视频中听老师亲自讲.
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;h2&gt;tran set/ dev set的分布不同&lt;/h2&gt;
&lt;p&gt;机器学习是需要大量数据喂出来的, 但有时候你很难获得大量最终应用场景需要的数据, 比如识别猫的照片, 从网上很容易下载比如可以找到200k, 但从手机中找到拍摄的照片相对要少一些比如可以找到10k. 因此也没法保证dev/test set和train set的数据分布是一致的.&lt;/p&gt;
&lt;h3&gt;不建议的方法&lt;/h3&gt;
&lt;p&gt;不要把下载来的数据和手机中的数据随机混合后分成train /dev/test set.&lt;/p&gt;
&lt;h3&gt;建议的方法&lt;/h3&gt;
&lt;p&gt;至少保证dev / test set中的数据是来自于目标应用场景的. 如果还剩下些手机照片的数据可以混合到train set中&lt;/p&gt;
&lt;h2&gt;分布不同时的错误率分析&lt;/h2&gt;
&lt;p&gt;bias=train error - bayes error
variance= dev error- train error&lt;/p&gt;
&lt;p&gt;既然dev set和train set的分布都不同, 那么肯定variance显得很大, 但是否真的就是因为过拟合了还是因为分布不同导致?&lt;/p&gt;
&lt;p&gt;解决方案是把train set里面再分出一小部分train_dev set, 这一部分的data set不要用在训练中, 用来检测的.&lt;/p&gt;
&lt;p&gt;那么:
&lt;em&gt; bias=train error - bayes error
&lt;/em&gt; variance= train_dev error- train error
* mismatch= dev error - train_dev error&lt;/p&gt;
&lt;p&gt;就可以单独把各个错误率区分出来了, 还是使用bias和variance来分析是欠拟合还是过拟合. mismatch的部分要单独考虑.&lt;/p&gt;
&lt;h2&gt;分布不同时的误差分析&lt;/h2&gt;
&lt;p&gt;还是先做手工标注, 看看mismatch的原因到底是怎样的. 有些可以用一些技术手段解决, 比如螺旋桨战斗机机炮打断螺旋桨这种事情.&lt;/p&gt;
&lt;p&gt;当然理想的解决方案还是找到足够多的目标场景数据了. 实在是找不到, 也许能够人工生成, 比如语音+噪音=有噪音环境的语音. 但是人工生成的时候要小心谨慎:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;人工生成的数据很可能多样性不足, 比如从赛车游戏中提取图像进行自动驾驶训练, 理论上不错, 但实际上车型很少, 可能只有20多种车辆样式.&lt;/li&gt;
&lt;li&gt;即使人眼看不出有什么差别, 在数据上不一定是相同的. 人工生成的数据可能只占了真实场景分布中的很小一部分.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong/</guid><pubDate>Mon, 18 Dec 2017 17:23:16 GMT</pubDate></item><item><title>机器学习的战略(3)--误差分析</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;p&gt;我觉得这一部分是导师指导/监督学生实验时应该出手的部分.&lt;/p&gt;
&lt;h2&gt;误差分析&lt;/h2&gt;
&lt;p&gt;这是个手工分析操作技巧了. 老师在课程中不断强调不要看不起手工分析, 一是人类看图识别的效率很高, 看上100张图很快就搞定了, 二是在分析过程中还有助于产生直观的印象, 再次利用人类强大的识别能力来解决问题.
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;p&gt;方法是:
&lt;em&gt; 从 &lt;strong&gt;dev set&lt;/strong&gt; 中, 找100个被标记错误的图片, 人眼看, 手工数.
&lt;/em&gt; 怎么数呢? 要列一张表, 要比较容易编辑扩展的, 我觉得excel之类的就不错.
&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;图片编号&lt;/th&gt;
&lt;th align="left"&gt;这是狗&lt;/th&gt;
&lt;th align="left"&gt;狮子老虎&lt;/th&gt;
&lt;th align="left"&gt;图片太模糊&lt;/th&gt;
&lt;th align="left"&gt;Instagram滤镜&lt;/th&gt;
&lt;th align="left"&gt;备注&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;1&lt;/td&gt;
&lt;td align="left"&gt;+1&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;+1&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;2&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;+1&lt;/td&gt;
&lt;td align="left"&gt;+1&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;3&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;+1&lt;/td&gt;
&lt;td align="left"&gt;+1&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;下雨天&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;...&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;...&lt;/td&gt;
&lt;td align="left"&gt;...&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;合计&lt;/td&gt;
&lt;td align="left"&gt;8%&lt;/td&gt;
&lt;td align="left"&gt;43%&lt;/td&gt;
&lt;td align="left"&gt;61%&lt;/td&gt;
&lt;td align="left"&gt;12%&lt;/td&gt;
&lt;td align="left"&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;有了这样的表格, 就很容易分析应该在哪些方面改进了.&lt;/p&gt;
&lt;h2&gt;标注错误&lt;/h2&gt;
&lt;p&gt;dataset的图片标注通常也是由人类来完成的, 也可能有各种不小心的错误, 如果你发现dataset中的图片有标注错误怎么办?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;随机出现的错误, 算了不管.&lt;/li&gt;
&lt;li&gt;系统性的错误, 比如大量的白狗被标记成了猫&lt;ul&gt;
&lt;li&gt;进行误差分析，看看标注错误有多大影响&lt;/li&gt;
&lt;li&gt;如果影响很大, 在dev / test set中一起改&lt;/li&gt;
&lt;li&gt;如果有精力, 也注意那些识别"正确"的图&lt;/li&gt;
&lt;li&gt;train set中的标注错误可改可不改.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/</guid><pubDate>Mon, 18 Dec 2017 17:23:01 GMT</pubDate></item><item><title>机器学习的战略(2)--错误率</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;h2&gt;与人类相比较&lt;/h2&gt;
&lt;p&gt;机器学习的很多任务, 比如识别图像, 听语音, 都是人类非常擅长的. 所以这些任务来说人类的错误率都相当低. 当然人类也分人, 看眼底图的还是得后节大夫, 找普通人看也还是错误率很高的, 最高的准确率应该是一组后节专家讨论会诊后得到的.
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;p&gt;理论上识别的错误率会有一个极限低值, 叫Bayes optimal error. 按照极限低值的定义, 那么肯定是比人类要低的, 但也不一定能够达到0, 在有些人类擅长的项目上, 不妨可以近似将人类的错误率当作bayes optimal error.&lt;/p&gt;
&lt;h2&gt;错误率分析&lt;/h2&gt;
&lt;p&gt;训练好的模型, 可以测定某一模型在dataset中的错误率, 重要的是3个数:
&lt;em&gt; bayes optimal error, 这是极限值, 不可测, 但在图像识别上可以近似用人类错误率替代.
&lt;/em&gt; train error, 模型用在train set上的错误率
* dev error, 模型用在dev set上的错误率&lt;/p&gt;
&lt;p&gt;有这三个数就好办了. 之前含混不清, 我连中文译名都不想给的bias 和 variance 终于可以定义了:
&lt;em&gt; bias=train error - bayes optimal error
&lt;/em&gt; variance=dev error - train error&lt;/p&gt;
&lt;p&gt;比如某个任务, 人类可以达到1%的错误率,&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型A&lt;/strong&gt;, train error=7%, dev error=8%
那么:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bias=7%-1%=6%&lt;/li&gt;
&lt;li&gt;variance=8%-7%=1%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显然这样的bias太高了, 模型还没练好, 欠拟合了.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;模型B&lt;/strong&gt;, train error=1.5%, dev error=7.5%&lt;/p&gt;
&lt;p&gt;那么:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;bias=1.5%-1%=0.5%&lt;/li&gt;
&lt;li&gt;variance=7.5%-1.5%=6%&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;显然是variance太高了, 过拟合了. 模型"记住"了train set的内容.&lt;/p&gt;
&lt;h2&gt;降低错误率的策略&lt;/h2&gt;
&lt;p&gt;先算错误率
&lt;em&gt; bias=train error - bayes optimal error(~人类错误率)
&lt;/em&gt; variance=dev error - train error&lt;/p&gt;
&lt;p&gt;bias又被成为avoidable error, 可改善的错误率.&lt;/p&gt;
&lt;h3&gt;降低bias&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;试试更大的模型, 比如神经网络层数更多, 每层的神经元更多之类.&lt;/li&gt;
&lt;li&gt;延长训练时间&lt;/li&gt;
&lt;li&gt;调整优化算法, 比如试试更华丽的momentum, RMS prop, ADOM.&lt;/li&gt;
&lt;li&gt;换更华丽的模型, 卷积神经网络CNN. RNN&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;降低variance&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;更多的数据, 更多的数据, 更多的数据&lt;/li&gt;
&lt;li&gt;Regularization, 就是加一些约束条件, 使得拟合出来的函数平滑一些, 不要那么扭曲妖娆.&lt;/li&gt;
&lt;li&gt;换更华丽的模型, CNN, RNN. 从2012年到现在, 甚至未来几年, 各种神经网络就像选秀一样, 差不多每个月都能有新的选手出现.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;此处推荐一下&lt;a href="https://www.jiqizhixin.com/"&gt;机器之心&lt;/a&gt;的网站和公众号. 一些重要论文会有概述.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/</guid><pubDate>Mon, 18 Dec 2017 17:22:47 GMT</pubDate></item><item><title>机器学习的战略(1)--目标的设置</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;h2&gt;调整ML模型的战略&lt;/h2&gt;
&lt;p&gt;用来描述模型结构的, 比如是y=kx+b, 还是y=ax^2+bx+c, 可能还有y=ax^3+bx^2+cx+d, 叫做"超参数" &lt;strong&gt;hyperparamter&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;调整hyperparamter是一件很麻烦的事情, 以至于很多人把这件事叫做"炼丹". 你可能需要炼上七七四十九天才知道, 哦, 原来y=kx+b这个线性模型不合适啊. 所以除了具体的调整方法(战术), 你还需要战略方案.
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;h3&gt;Orthogonalization&lt;/h3&gt;
&lt;p&gt;正交化, 很学术的名词. 其实就是一次调一个东西, 别混在一起调整! 如果你的车方向盘和油门是关联在一起的, 那肯定就没法开了.&lt;/p&gt;
&lt;p&gt;这大概是所有科研\研发的基本战略概念了.&lt;/p&gt;
&lt;h2&gt;ML的目标设置&lt;/h2&gt;
&lt;h3&gt;确定单一评价目标&lt;/h3&gt;
&lt;p&gt;用一个数来描述你的目标. 比如准确率, 其实是有两个数来描述的:
&lt;em&gt; Precision: 模型标定为阳性的数据(比如模型认为是猫的图片), 有多少实际是阳性的(图片真的是猫).
&lt;/em&gt; Recall:  在阳性的数据中(图片中真的是猫), 有多少被模型找出来了&lt;/p&gt;
&lt;p&gt;(&lt;strong&gt;我特别讨厌用相似的名词去描述相近或者相反的概念, 每次我都弄混, 所以此处不出现真阳性假阳性之类的名词&lt;/strong&gt;)&lt;/p&gt;
&lt;p&gt;显然是希望两个值都很高, 但是会碰到鱼和熊掌的问题
比如有两个模型:

| 分类器 | Precision | Recall |
| :----| :---- |:---- |
|A|95%|90%|
|B|98%|85%|&lt;/p&gt;
&lt;p&gt;那么用Precision与Recall调和平均数代替:&lt;/p&gt;
&lt;p&gt;F1 score= 2/(1/Precision+1/Recall)&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;分类器&lt;/th&gt;
&lt;th align="left"&gt;Precision&lt;/th&gt;
&lt;th align="left"&gt;Recall&lt;/th&gt;
&lt;th align="left"&gt;F1 score&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;A&lt;/td&gt;
&lt;td align="left"&gt;95%&lt;/td&gt;
&lt;td align="left"&gt;90%&lt;/td&gt;
&lt;td align="left"&gt;92.4%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;B&lt;/td&gt;
&lt;td align="left"&gt;98%&lt;/td&gt;
&lt;td align="left"&gt;85%&lt;/td&gt;
&lt;td align="left"&gt;91.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3&gt;区分Satisficing 和 Optimizing metric&lt;/h3&gt;
&lt;p&gt;还是区分目标的事情, 你会希望准确率高, 又希望算得快, 还希望用计算资源少, 这几项很难同时达成, 于是要区分目标, 哪些是必须要满足的Satisficing metric, 满足条件就行了, 哪些是要尽量优化的, 越高越好的Optimizing metric.&lt;/p&gt;
&lt;p&gt;比如甲方要求分类器能够在10秒内给出结果, 占用内存不超过10M, 准确率越高越好. 那么下面几个分类器:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align="left"&gt;分类器&lt;/th&gt;
&lt;th align="left"&gt;F1 score&lt;/th&gt;
&lt;th align="left"&gt;时间&lt;/th&gt;
&lt;th align="left"&gt;内存&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align="left"&gt;A&lt;/td&gt;
&lt;td align="left"&gt;99%&lt;/td&gt;
&lt;td align="left"&gt;20秒&lt;/td&gt;
&lt;td align="left"&gt;5M&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;B&lt;/td&gt;
&lt;td align="left"&gt;98%&lt;/td&gt;
&lt;td align="left"&gt;9秒&lt;/td&gt;
&lt;td align="left"&gt;9M&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align="left"&gt;C&lt;/td&gt;
&lt;td align="left"&gt;96%&lt;/td&gt;
&lt;td align="left"&gt;3秒&lt;/td&gt;
&lt;td align="left"&gt;5M&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;显然选B方案.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;其实还是没钱!&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;train/dev/test set的分布&lt;/h3&gt;
&lt;p&gt;dev/test set是目标, 相当于靶子, 所以dev/ test set的分布要尽量接近真实场景. 如果立错了靶子就很麻烦.&lt;/p&gt;
&lt;p&gt;比如要做手机照相识别的分类器app, 用从网上下载的图库可能就太清晰了, 图库通常是专业摄影师拍摄的, 而手机照片往往模糊\曝光不足\抖动. . . 各种问题, 如果dev/test set还是专业摄影师拍摄的图, 那么到用户手里的时候, 可能效果就不好.&lt;/p&gt;
&lt;h3&gt;train/dev/test set的数量分配&lt;/h3&gt;
&lt;p&gt;dataset的数量=train+dev+test set的数量.
机器学习中dataset是越大越好, 在现在的机器学习项目中, dataset往往很大很大, 有了网络以后有大量的照片可以用. 那么dev/ test set的比例就不需要很高, 绝对数量足够就可以了.&lt;/p&gt;
&lt;p&gt;如果dataset有1000k张图片, 那么
train: dev: test= 98%: 1%: 1%
test set大概10k张图片就可以了.&lt;/p&gt;
&lt;h3&gt;何时修正dev/test set和metrics&lt;/h3&gt;
&lt;p&gt;有时候你的模型看起来错误率很低, 准确性不错, 各项指标都很好, 但如果不慎挑出来一堆色情图片, 那这样的模型也需要忍痛割爱, 否则后患无穷.&lt;/p&gt;
&lt;p&gt;如果出现了某些必须要满足的要求, 或者必须要避免的事件, 可以调整dev /test set来挪挪靶子, 或者在评价函数里面加上限定条件, 比如把色情图片作为罚分项目.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/</guid><pubDate>Mon, 18 Dec 2017 17:22:33 GMT</pubDate></item><item><title>机器学习的战略(0)--基础概念</title><link>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;p&gt;这是deeplearning.ai系列课程的第三门课&lt;a href="https://www.coursera.org/learn/machine-learning-projects/"&gt;Structuring Machine Learning Projects&lt;/a&gt;.  我觉得这门课非常适合甲方\导师\研发团队头目\产品经理.&lt;/p&gt;
&lt;p&gt;这是一门即时战略类课程, 讲述如何评估模型如何挑选改进方向, 所需基础知识不多, 对机器学习知道基本概念即可.
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;p&gt;但是这门课里面涉及到的概念和经验很多, 未来我可能需要借助一个笔记时常参考. 这个笔记也可以帮助其他未选这门课的人了解其中的梗概.&lt;/p&gt;
&lt;h2&gt;一些基础的概念&lt;/h2&gt;
&lt;p&gt;虽然我认为这门课所需要的基础知识并不多, 但也还是需要知道一些机器学习的基本概念, 需要量还是要比"朋友圈公众号科普"多一些.&lt;/p&gt;
&lt;h3&gt;机器学习 Machine Learning&lt;/h3&gt;
&lt;p&gt;这里讲的是有监督学习的任务, 比如给一张照片, 判定这张照片是不是一只猫. 所谓有监督的学习, 就是已知有很多照片, 已经被人工标记过是猫还是非猫了, 这些叫做数据集&lt;strong&gt;dataset&lt;/strong&gt;, 数据集中通常是一个对应的结构, 一个输入x, 对应一个输出y.  x -&amp;gt;y, 比如一张照片就是x, 是猫的照片y=1, 不是猫的照片 y=0&lt;/p&gt;
&lt;p&gt;Machine Learning就是利用大量的dataset, 自动从里面去总结出一种从x映射到y的规律.&lt;/p&gt;
&lt;p&gt;最简单的, 比如线性拟合就可以视为一种简单的ML, 有一堆数据点(x,y), 用一条直线去拟合它们. 求解y=kx+b, 有了y=kx+b的公式以后, 你就可以代入一些新的x, 求出y值.&lt;/p&gt;
&lt;p&gt;y=kx+b这个训练出来的公式通常叫做"模型", 当然你的数据也可能不是符合y=kx+b的, 而是符合y=ax^2+bx+c, 甚至于更加复杂的函数关系以至于很难写出表达式. 去找到k, b这样的参数的过程叫做"训练"模型.&lt;/p&gt;
&lt;p&gt;除了拟合, 更常见的Machine Learning问题是分类, 其实也类似, 比如相当于看是否 y=kx+b&amp;gt;0&lt;/p&gt;
&lt;p&gt;在deeplearning.ai课程中的&lt;a href="https://www.coursera.org/learn/neural-networks-deep-learning/home"&gt;第一门课&lt;/a&gt;就是讲基本的ML方法----神经网络.&lt;/p&gt;
&lt;h3&gt;dataset&lt;/h3&gt;
&lt;p&gt;有标记的数据集x-&amp;gt;y, 就是dataset. 现代的机器学习已经开始使用非常庞大的数据集了, 比如1,000,000张标记好的照片甚至更多. &lt;/p&gt;
&lt;p&gt;在训练模型时, 需要把dataset分成几个部分, 一般而言是分成3个, train set / develop set / test set.&lt;/p&gt;
&lt;h4&gt;train set&lt;/h4&gt;
&lt;p&gt;train set是用来训练当前这个模型用的, 比如假定模型是y=kx+b, 求解k和b这两个参数的过程就是用train set.&lt;/p&gt;
&lt;p&gt;不严格的说, 相当于上课时老师用的例题.&lt;/p&gt;
&lt;h4&gt;develop set&lt;/h4&gt;
&lt;p&gt;develop set, 在课程中常写作dev set 是说你可能有多个候选的模型, 或者说要"develop"模型的时候, 用来测试各个模型的. 比如你的候选模型除了y=kx+b, 可能还有y=ax^2+bx+c, 可能还有y=ax^3+bx^2+cx+d... 这时候就要分别用同一个train set去训练各个模型, 求得各自最佳的参数, 然后再用dev set中的数据代入, 看看各个模型的误差是怎样的.&lt;/p&gt;
&lt;p&gt;不严格的说, 相当于家庭作业.  &lt;/p&gt;
&lt;h4&gt;test set&lt;/h4&gt;
&lt;p&gt;test set, 顾名思义, 就是用来测验考试的. 考试题里不能是老师上课用过的例题, 也不能是做过的作业, 需要是考生(模型)从来没见过的题目.&lt;/p&gt;
&lt;h3&gt;bias 和 variance&lt;/h3&gt;
&lt;p&gt;我觉得这两个词语的中文翻译并不准确, 所以干脆不翻译了.

* bias过高, 是指拟合的函数不够准确, 比如本来数据是符合y=a^x+bx+c这样一条二次曲线的, 结果只用了y=kx+b一条直线去拟合, 直的适应不了弯的, 于是可能在一小段还比较符合, 在其他区域预测的准确率就很差. 通常认为bias过高, 是拟合不足, 欠拟合的. under fitting. [插图]&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;variance过高, 是指拟合过度了, over fitting. 一条弯弯曲曲的曲线穿过所有的数据点, 这样虽然误差很小, 但是预测能力就很差, 而我们进行机器学习当然目的是为了评估哪些未知的数据. 真正需要的是预测能力.[插图]&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果模型过于简单, bias就容易很高, 如果模型过于复杂, variance就容易很高.&lt;/p&gt;
&lt;p&gt;在deeplearning.ai系列课程的&lt;a href="https://www.coursera.org/learn/deep-neural-network/home/welcome"&gt;第二门&lt;/a&gt;就是在讲各种奇技淫巧去调整模型来降低bias和variance, 相当于改善模型表现的战术方法.&lt;/p&gt;
&lt;p&gt;我个人觉得理解上面这些概念就可以开始ML strategy这门课程的学习了. 但是我已经学过了第一门和第二门课, 有可能存在"因为我知道所以我不知道你是否需要知道"这样的知识诅咒. 所以万一在学MLstrategy这门课程时觉得吃力, 还是去补习一下基础比较好. 暂时没必要去学更复杂的卷积神经网络什么的.&lt;/p&gt;
&lt;hr&gt;
&lt;h2&gt;参考资料:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;机器学习的战略合集目录:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/"&gt;基础概念&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-1-mu-biao-de-she-zhi/"&gt;目标设置&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-2-cuo-wu-lu/"&gt;错误率&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-3-wu-chai-fen-xi/"&gt;误差分析&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-4-mian-dui-fen-bu-bu-tong"&gt;面对分布不同&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-5-qian-yi-xue-xi"&gt;迁移学习&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-6-end-to-end/"&gt;end-to-end&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;课程链接:
&lt;a href="https://www.coursera.org/learn/machine-learning-projects/home/welcome"&gt;Structuring Machine Learning Projects&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;参考视频:
莫烦的"&lt;a href="https://morvanzhou.github.io/tutorials/machine-learning/ML-intro/"&gt;有趣的机器学习&lt;/a&gt;"系列科普视频, 制作精良讲解清晰, 非常推荐.  &lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;&lt;/div&gt;</description><category>ML</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/Machine_Learning/ML_strategy/ji-qi-xue-xi-de-zhan-lue-0-ji-chu-gai-nian/</guid><pubDate>Mon, 18 Dec 2017 17:22:18 GMT</pubDate></item><item><title>为什么对比敏感度的视标亮度是正弦变化的？(5)</title><link>https://goldengrape.github.io/posts/ophthalmology/CSF/wei-shi-yao-dui-bi-min-gan-du-de-shi-biao-liang-du-shi-zheng-xian-bian-hua-de-5/</link><dc:creator>Golden Grape</dc:creator><description>&lt;div&gt;&lt;p&gt;前面说到测量对比敏感度所需要的视标，应该是经过任意像差的角膜、晶状体，在视网膜上成像以后，它的空间频率应当和经过一个理想无像差的眼睛一样。
&lt;!-- TEASER_END --&gt;&lt;/p&gt;
&lt;h2&gt;为什么要用Eigenfunction&lt;/h2&gt;
&lt;p&gt;如果空间频率不一样，就会有麻烦，比如医生想测量的是相对高频部分的30 cpd(cycle per degree,周/度，在一度范围内空间结构重复了多少次，这是空间频率的单位)，如果由于患者眼有像差的存在，也许在视网膜上的成像变成了20cpd，本来患者无法分辨的视标，反而因为像差因祸得福可以指出方向了。&lt;/p&gt;
&lt;p&gt;类比测视力，就好像用1.0的视标去测病人，结果病人自带放大系统，视标放大到0.1的程度，这样的测量就错了。&lt;/p&gt;
&lt;p&gt;由于病人的像差可以千奇百怪千差万别，所以病人的眼睛作为一个线性不变系统，也可能是千差万别的。要选择一个带有周期结构的输入，经过各种各不相同的线性系统还可以得到同周期的输出，满足这个能力的输入，就是所有线性不变系统的Eigenfunction了。&lt;/p&gt;
&lt;p&gt;常规的E视标，相当于给入的输入的“方波”，那么如果经过一个有像差的眼睛，成像后的输出可能是这样的：&lt;/p&gt;
&lt;p&gt;&lt;img alt="E_MTF" src="https://goldengrape.github.io/images/CSF/E_MTF.png"&gt;&lt;/p&gt;
&lt;p&gt;看输出的强度波形，会发现各个峰的高度是不同的，如果仔细测量，可能还会发现波峰之间的周期也会略有差别。甚至一个有经验的“视力测量欺骗者”，可以根据虚影的方向反推出视标的方向。&lt;/p&gt;
&lt;p&gt;但如果是一个正弦波的视标。&lt;/p&gt;
&lt;p&gt;&lt;img alt="sin_MTF" src="https://goldengrape.github.io/images/CSF/sin_MTF.png"&gt;&lt;/p&gt;
&lt;p&gt;经过同样有像差的眼，形成的仍然是正弦波，峰值是同样的，周期是同样的，区别只是“振幅”发生了变化。只有对比度这个变量会根据像差的情况改变，这样就方便了测量。&lt;/p&gt;
&lt;h2&gt;总结&lt;/h2&gt;
&lt;p&gt;为什么对比敏感度的视标亮度是正弦变化的？&lt;/p&gt;
&lt;p&gt;答：因为人眼视觉成像过程近似于线性不变系统，亮度正弦变化的视标是线性系统的Eigenfunction，在经过人眼成像厚视标的空间频率不变。&lt;/p&gt;
&lt;p&gt;至于为什么正弦函数是线性不变系统的Eigenfunction，就是另外一个很长的故事了。如果有兴趣可以参考吕乃光老师编写的《傅里叶光学(第二版)》，第50-52页。&lt;/p&gt;
&lt;h2&gt;One more thing&lt;/h2&gt;
&lt;p&gt;题图&lt;/p&gt;
&lt;p&gt;&lt;img alt="stripe_0.21" src="https://goldengrape.github.io/images/CSF/stripe_0.21.jpg"&gt;&lt;/p&gt;
&lt;p&gt;很多人抱怨说看起来很不舒服。这是有道理的。因为人眼在对焦的时候可能是在不断测试是否看得“清晰”，至于“清晰”是可以有定义的。常见的方法是去比较图像中高频部分和低频部分的对比度。&lt;/p&gt;
&lt;p&gt;通常低频部分的对比度随着离焦变化是比较慢的，就像你戴上从-3.00D到+3.00D的眼镜都可以分辨出0.1的视标。而高频部分只有在对焦清楚的时候对比度才最大——你只有找到合适的眼镜看1.0的视标才最清晰。&lt;/p&gt;
&lt;p&gt;如果你眼前大范围的区域都是单一空间频率的正弦视标，就像题图中的那样，甚至如果整间屋子都是同一正弦函数。你的眼睛就失去了对焦的参照，因为只有一个空间频率了，所以会感觉不适。&lt;/p&gt;&lt;/div&gt;</description><category>CSF</category><category>教程</category><category>现代眼科医生知识扩展包</category><guid>https://goldengrape.github.io/posts/ophthalmology/CSF/wei-shi-yao-dui-bi-min-gan-du-de-shi-biao-liang-du-shi-zheng-xian-bian-hua-de-5/</guid><pubDate>Mon, 18 Dec 2017 17:11:00 GMT</pubDate></item></channel></rss>